{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "#import pandas as pd\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "PATH = Path('.')\n",
    "\n",
    "training_file = '../input/german-traffic-sign/train.p'\n",
    "validation_file = '../input/german-traffic-sign/valid.p' \n",
    "testing_file = '../input/german-traffic-sign/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(X_train)\n",
    "\n",
    "# TODO: Number of validation examples\n",
    "n_validation = len(X_valid)\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(set(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "signnames = pd.read_csv('../input/signnames/signnames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classID_signames = list(signnames['SignName'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data exploration visualization code goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "train_unique_indexs = list(np.unique(y_train, return_index=True)[1])\n",
    "rows = len(train_unique_indexs)//4 + 1\n",
    "f = plt.figure(figsize=(20, 16))\n",
    "for i, index in enumerate(train_unique_indexs, 1):\n",
    "    plt.subplot(rows, 4, i)\n",
    "    plt.imshow(X_train[train_unique_indexs[i-1]])\n",
    "    plt.axis('off')\n",
    "    plt.title(classID_signames[i-1])\n",
    "    plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.5, wspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.layers import (Conv2D, MaxPooling2D,\n",
    "                          Input, Flatten, Dense, \n",
    "                          BatchNormalization, \n",
    "                          Activation, AveragePooling2D,\n",
    "                          GlobalAveragePooling2D,LeakyReLU, Dropout, Add)\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_valid = np_utils.to_categorical(y_valid)\n",
    "y_test = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "classes = 43\n",
    "X_input = Input(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerminateOnBaseline(Callback):\n",
    "    \"\"\"Callback that terminates training when either acc or val_acc reaches a specified baseline\n",
    "    \"\"\"\n",
    "    def __init__(self, monitor='acc', baseline=0.9):\n",
    "        super(TerminateOnBaseline, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.baseline = baseline\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        acc = logs.get(self.monitor)\n",
    "        if acc is not None:\n",
    "            if acc >= self.baseline:\n",
    "                print('Epoch %d: Reached baseline, terminating training' % (epoch))\n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [TerminateOnBaseline(monitor='val_acc', baseline=0.97)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(X, channel):\n",
    "    X_short = X\n",
    "    X = Conv2D(channel, (1, 1), strides = (1, 1), kernel_initializer='he_normal',use_bias=False, kernel_regularizer=l2(1e-4))(X)\n",
    "    X = Conv2D(channel, (1, 1), strides = (1, 1), kernel_initializer='he_normal',use_bias=False, kernel_regularizer=l2(1e-4))(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Add()([X, X_short])##############\n",
    "    X = LeakyReLU(alpha=0.1)(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_conv(X, channel, f, s):\n",
    "    X = Conv2D(channel, (f, f), strides = (s, s), kernel_initializer='he_normal')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU(alpha=0.1)(X)\n",
    "    return X\n",
    "\n",
    "def conv(X, channel, f, s):\n",
    "    X = Conv2D(channel, (f, f), strides = (s, s), kernel_initializer='he_normal')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU(alpha=0.1)(X)\n",
    "    X = Conv2D(channel, (1, 1), strides = (1, 1), kernel_initializer='he_normal')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = simple_conv(X_input, 64, 3, 2)\n",
    "\n",
    "X = resnet(X, 64)\n",
    "X = conv(X, 128, 3, 2)\n",
    "X = resnet(X, 128)\n",
    "X = conv(X, 256, 1, 1) # test\n",
    "X = resnet(X, 256) # test\n",
    "X = conv(X, 512, 3, 2)\n",
    "X = resnet(X, 512)\n",
    "X = conv(X, 1024, 3, 2)\n",
    "X = resnet(X, 1024)\n",
    "\n",
    "X = simple_conv(X, 128, 1, 1)\n",
    "X = simple_conv(X, 128, 1, 1)\n",
    "\n",
    "X = GlobalAveragePooling2D()(X)\n",
    "X = BatchNormalization()(X) # imp\n",
    "output = Dropout(0.25)(X)\n",
    "output = Dense(512, activation='relu')(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = Dropout(0.5)(output)\n",
    "out = Dense(43, activation='softmax')(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = X_input, outputs = out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20, batch_size=32, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = model.predict(X_valid)\n",
    "valid_score = len(y_valid[y_valid.argmax(axis=1)==valid.argmax(axis=1)])/len(y_valid)\n",
    "print(f\"Validation Score = {valid_score*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = model.predict(X_test)\n",
    "test_score = len(y_test[y_test.argmax(axis=1)==y_test_predict.argmax(axis=1)])/len(y_test)\n",
    "print(f\"Test Score = {test_score*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_internet = glob.glob('../input/internet-images/*.jpg')\n",
    "img_internet = np.array([plt.imread(i) for i in img_internet])\n",
    "img_internet = img_internet/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(20, 16))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(img_internet[i])\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.5, wspace=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_internet = model.predict(img_internet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_internet_id = predict_internet.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(20, 16))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(img_internet[i])\n",
    "    plt.title(f'predicted = {classID_signames[predict_internet_id[i]]}')\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.5, wspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images = 5\n",
    "correct_prediction = 2\n",
    "accuracy = 2/5*100\n",
    "print(f\"accuracy of images found on internet = {accuracy} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(predict_internet, axis=1)[:,::-1][:,:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(predict_internet, axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
